{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhishekSatpathy4848/SpeechEmotionRecognition/blob/main/SpeechEmotionRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6fmoCayVyd5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas\n",
        "import numpy\n",
        "import librosa\n",
        "import librosa.display\n",
        "import librosa.feature\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import seaborn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
        "numpy.set_printoptions(suppress=True,formatter={'float_kind':'{:f}'.format})\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agwGCXRAGZoY"
      },
      "outputs": [],
      "source": [
        "paths=[]\n",
        "label=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzwdR1kxRREY"
      },
      "outputs": [],
      "source": [
        "dnew={}\n",
        "x=\"./drive/MyDrive/TESS Toronto emotional speech set data\"\n",
        "for i in os.listdir(x):\n",
        "  emotion=i[4:].lower()\n",
        "  path=x+\"/\"+i\n",
        "  s=os.listdir(path)\n",
        "  for j in s:\n",
        "    complete_audio_file_path=path+\"/\"+j\n",
        "    paths.append(complete_audio_file_path)\n",
        "    label.append(emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy22r_BfA970"
      },
      "outputs": [],
      "source": [
        "x=\"./drive/MyDrive/ALL\"\n",
        "for i in os.listdir(x):\n",
        "  p=x+\"/\"+i\n",
        "  paths.append(p)\n",
        "  if \"_su\" in i:\n",
        "    label.append(\"pleasant_surprise\")\n",
        "  elif \"_a\" in i:\n",
        "    label.append(\"angry\")\n",
        "  elif \"_d\" in i:\n",
        "    label.append(\"disgust\")\n",
        "  elif \"_sa\" in i:\n",
        "    label.append(\"sad\")\n",
        "  elif \"_n\" in i:\n",
        "    label.append(\"neutral\")\n",
        "  elif \"_h\" in i:\n",
        "    label.append(\"happy\")\n",
        "  elif \"_f\" in i:\n",
        "    label.append(\"fear\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0L7A2FwIxyG"
      },
      "outputs": [],
      "source": [
        "x=\"./drive/MyDrive/AudioWAV\"\n",
        "for i in os.listdir(x):\n",
        "  p=x+\"/\"+i\n",
        "  paths.append(p)\n",
        "  if \"_ANG\" in i:\n",
        "    label.append(\"angry\")\n",
        "  elif \"_DIS\" in i:\n",
        "    label.append(\"disgust\")\n",
        "  elif \"_SAD\" in i:\n",
        "    label.append(\"sad\")\n",
        "  elif \"_NEU\" in i:\n",
        "    label.append(\"neutral\")\n",
        "  elif \"_HAP\" in i:\n",
        "    label.append(\"happy\")\n",
        "  elif \"_FEA\" in i:\n",
        "    label.append(\"fear\")\n",
        "dnew={\"Emotion\":label,\"Path\":paths}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjAmnCkyL17H"
      },
      "outputs": [],
      "source": [
        "x=\"./drive/MyDrive/archive\"\n",
        "for i in os.listdir(x):\n",
        "  h=x+\"/\"+i\n",
        "  y=os.listdir(h)\n",
        "  for j in y:\n",
        "    p=h+\"/\"+j\n",
        "    paths.append(p)\n",
        "    if j[6:8]==\"01\":\n",
        "      label.append(\"neutral\")\n",
        "    elif j[6:8]==\"02\":\n",
        "      label.append(\"calm\")\n",
        "    elif j[6:8]==\"03\":\n",
        "      label.append(\"happy\")\n",
        "    elif j[6:8]==\"04\":\n",
        "      label.append(\"sad\")\n",
        "    elif j[6:8]==\"05\":\n",
        "      label.append(\"angry\")\n",
        "    elif j[6:8]==\"06\":\n",
        "       label.append(\"fear\")\n",
        "    elif j[6:8]==\"07\":\n",
        "      label.append(\"disgust\")\n",
        "    elif j[6:8]==\"08\":\n",
        "      label.append(\"pleasant_surprise\")\n",
        "dnew={\"Emotion\":label,\"Path\":paths}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4u96IHXWEE8"
      },
      "outputs": [],
      "source": [
        "Audio_DataFrame=pandas.DataFrame(dnew)\n",
        "Audio_DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TptjCYYU1cp3"
      },
      "outputs": [],
      "source": [
        "Audio_DataFrame.to_csv(\"./drive/MyDrive/IEEE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfglbDrWTEYd"
      },
      "outputs": [],
      "source": [
        "print(Audio_DataFrame.groupby([\"Emotion\"])[\"Emotion\"].count())\n",
        "Count_Emotion=numpy.array(Audio_DataFrame.groupby([\"Emotion\"])[\"Emotion\"].count())\n",
        "print(Count_Emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRpHcPqkUiMl"
      },
      "outputs": [],
      "source": [
        "Unique_Emo=numpy.sort(Audio_DataFrame.Emotion.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF2k8vu9W2ak"
      },
      "outputs": [],
      "source": [
        "Bar_Plot_Dictionary={\"Emotion\":Unique_Emo,\"Count\":Count_Emotion}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTdo1vOCZsU5"
      },
      "outputs": [],
      "source": [
        "Bar_Plot_DataFrame=pandas.DataFrame(Bar_Plot_Dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwS5qvilYfMk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "seaborn.barplot(x=\"Emotion\",y=\"Count\",data=Bar_Plot_DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksxNb5YKdeuQ"
      },
      "outputs": [],
      "source": [
        "def Display_Amplitude_Time_Waveplot(audio_path):\n",
        "  l,sr=librosa.load(audio_path)\n",
        "  plt.figure(figsize=(25,20))\n",
        "  librosa.display.waveplot(l,alpha=0.8)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhAOBiXCp67l"
      },
      "outputs": [],
      "source": [
        "def Frequency_Spectrum(audio_path):\n",
        "  l,sr=librosa.load(audio_path)\n",
        "  Fast_Fourier_Transform=numpy.fft.fft(l)\n",
        "  Fast_Fourier_Transform=numpy.abs(Fast_Fourier_Transform)\n",
        "  frequency=numpy.linspace(0,sr,len(Fast_Fourier_Transform))\n",
        "  num_frequency_bins=int(len(frequency)/2)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  plt.plot(frequency[:num_frequency_bins],Fast_Fourier_Transform[:num_frequency_bins])\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiBSekOTZAHL"
      },
      "outputs": [],
      "source": [
        "def Mel_Spectrogram(audio_path,frame_length,hop_length,mel_bands):\n",
        "  l,sr=librosa.load(audio_path)\n",
        "  mel_spectrogram=librosa.feature.melspectrogram(l,sr=sr,n_fft=frame_length,hop_length=hop_length,n_mels=mel_bands)\n",
        "  mel_to_log=librosa.power_to_db(mel_spectrogram)\n",
        "  plt.figure(figsize=(15,10))\n",
        "  librosa.display.specshow(mel_to_log,sr=sr,hop_length=hop_length,x_axis=\"time\",y_axis=\"mel\")\n",
        "  plt.colorbar(format=\"%+2.f\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAw_arYoj1ul"
      },
      "outputs": [],
      "source": [
        "FRAME_SIZE=2048\n",
        "HOP_SIZE=512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "079OZxGnxHV3"
      },
      "outputs": [],
      "source": [
        "print(\"Fear\")\n",
        "P=Audio_DataFrame[\"Path\"][0]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wag5BQk5yD1x"
      },
      "outputs": [],
      "source": [
        "print(\"Sad\")\n",
        "P=Audio_DataFrame[\"Path\"][1]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzo_d5iu29nV"
      },
      "outputs": [],
      "source": [
        "print(\"Pleasant Surprise\")\n",
        "P=Audio_DataFrame[\"Path\"][943]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj06Dnt_29p5"
      },
      "outputs": [],
      "source": [
        "print(\"Happy\")\n",
        "P=Audio_DataFrame[\"Path\"][670]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYZEo4c-29vH"
      },
      "outputs": [],
      "source": [
        "print(\"Disgust\")\n",
        "P=Audio_DataFrame[\"Path\"][1321]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDLTXqHG294h"
      },
      "outputs": [],
      "source": [
        "print(\"Neutral\")\n",
        "P=Audio_DataFrame[\"Path\"][1527]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An_hCbX42-Wc"
      },
      "outputs": [],
      "source": [
        "print(\"Angry\")\n",
        "P=Audio_DataFrame[\"Path\"][3162]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3416vbu2-vt"
      },
      "outputs": [],
      "source": [
        "print(\"Calm\")\n",
        "P=Audio_DataFrame[\"Path\"][11601]\n",
        "Display_Amplitude_Time_Waveplot(P)\n",
        "Frequency_Spectrum(P)\n",
        "Mel_Spectrogram(P,FRAME_SIZE,HOP_SIZE,100)\n",
        "ipd.Audio(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgdLkg61lnPO"
      },
      "outputs": [],
      "source": [
        "def extract_features(signal):\n",
        "  zero_crossing_rate=librosa.feature.zero_crossing_rate(signal)[0]\n",
        "  rms=librosa.feature.rms(signal)[0]\n",
        "  mfccs=librosa.feature.mfcc(signal)\n",
        "  chr_stft=librosa.feature.chroma_stft(signal)\n",
        "  mel_spectrogram=librosa.feature.melspectrogram(signal)\n",
        "  mel_spec=librosa.power_to_db(mel_spectrogram)\n",
        "  return numpy.hstack((numpy.mean(zero_crossing_rate.T,axis=0),numpy.mean(chr_stft.T,axis=0),numpy.mean(mfccs.T,axis=0),numpy.mean(rms.T,axis=0),numpy.mean(mel_spec.T,axis=0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yXCroV9ICJ8"
      },
      "outputs": [],
      "source": [
        "def get_features(path):\n",
        "  audio,sr=librosa.load(path,duration=2.5,offset=0.6)\n",
        "\n",
        "  features_original=extract_features(audio) # original audio\n",
        "\n",
        "  noise=numpy.random.normal(0,audio.std(),audio.size)\n",
        "  augmented_noise=audio+noise*0.4\n",
        "  features_noise=extract_features(augmented_noise) # with white noise\n",
        "\n",
        "  augmented_time_stretch=librosa.effects.time_stretch(audio,0.8)\n",
        "  augmented_pitch_shift_on_time_stretch=librosa.effects.pitch_shift(augmented_time_stretch,sr,0.7) #pitch shift on time stretch audio\n",
        "  features_pitch_shift_on_time_stretch=extract_features(augmented_pitch_shift_on_time_stretch)\n",
        "\n",
        "  return numpy.vstack((features_original,features_noise,features_pitch_shift_on_time_stretch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhrippMkyETQ"
      },
      "outputs": [],
      "source": [
        "P=Audio_DataFrame[\"Path\"][1005]\n",
        "print(get_features(P).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXdtMUBgWWcE"
      },
      "outputs": [],
      "source": [
        "P=Audio_DataFrame[\"Path\"][101]\n",
        "audio,sr=librosa.load(P,duration=1)\n",
        "print(len(audio))\n",
        "librosa.get_duration(y=audio, sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXizk71BUBBq"
      },
      "outputs": [],
      "source": [
        "X=[]\n",
        "Y=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RdXnN_V0AIe"
      },
      "outputs": [],
      "source": [
        "iterations=int(len(Audio_DataFrame)/3)\n",
        "for i in range(0,iterations):\n",
        "  audio_file_features=get_features(Audio_DataFrame[\"Path\"][i])\n",
        "  for j in audio_file_features:\n",
        "    X.append(j)\n",
        "    Y.append(Audio_DataFrame[\"Emotion\"][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG-wqZVQwAhX"
      },
      "outputs": [],
      "source": [
        "for i in range(iterations,2*iterations):\n",
        "  audio_file_features=get_features(Audio_DataFrame[\"Path\"][i])\n",
        "  for j in audio_file_features:\n",
        "    X.append(j)\n",
        "    Y.append(Audio_DataFrame[\"Emotion\"][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ5kq0jWUFsc"
      },
      "outputs": [],
      "source": [
        "for i in range(2*iterations,3*iterations):\n",
        "  audio_file_features=get_features(Audio_DataFrame[\"Path\"][i])\n",
        "  for j in audio_file_features:\n",
        "    X.append(j)\n",
        "    Y.append(Audio_DataFrame[\"Emotion\"][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy6NCKZQUHZa"
      },
      "outputs": [],
      "source": [
        "Final_Emotion_Dict={\"Features\":X,\"Label\":Y}\n",
        "Final_DataFrame=pandas.DataFrame(Final_Emotion_Dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ6NhiJLz7_z"
      },
      "outputs": [],
      "source": [
        "Final_DataFrame.to_csv(\"./drive/MyDrive/Final_Emotion_DataFrame\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjxpbFyIQ4HA"
      },
      "outputs": [],
      "source": [
        "Final_DataFrame.to_csv(\"./drive/MyDrive/Final_Emotion_DataFrame2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6bDcC2dSfmm"
      },
      "outputs": [],
      "source": [
        "Final_DataFrame.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEPRfzvntYW0"
      },
      "outputs": [],
      "source": [
        "pandas.get_dummies(Final_DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLxpJ_IIuaTx"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded=pandas.get_dummies(Final_DataFrame[\"Label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08k6CMWLv1wV"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHNgOfnEa07q"
      },
      "outputs": [],
      "source": [
        "one_hot_encoded.to_csv(\"./drive/MyDrive/One_Hot_Encoded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqxApsRJhNpQ"
      },
      "outputs": [],
      "source": [
        "Final_Data_Sample.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVhh0NPdQxNX"
      },
      "outputs": [],
      "source": [
        "df=pandas.read_csv(\"/content/drive/MyDrive/Final_Emotion_DataFrame\")\n",
        "x=[]\n",
        "for s in Final_DataFrame[\"Features\"]:\n",
        "  l=eval(s.replace(\" \",\",\"))\n",
        "  x.append(l)\n",
        "  i+=1\n",
        "x=numpy.array(x)\n",
        "print(x.shape)\n",
        "print(x.size)\n",
        "x_test,x_train=train_test_split(x,)\n",
        "print(x_test.shape,x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7wxrrDPwP0u"
      },
      "outputs": [],
      "source": [
        "One_Hot_Encoding=pandas.read_csv(\"/content/drive/MyDrive/One_Hot_Encoded\")\n",
        "One_Hot_Encoded=numpy.array(One_Hot_Encoding)\n",
        "One_Hot_Encoded=One_Hot_Encoded[:,1:]\n",
        "one_hot_encoded=numpy.array(One_Hot_Encoded)\n",
        "Final_DataFrame=pandas.read_csv(\"/content/drive/MyDrive/Final_Emotion_DataFrame\")\n",
        "i=0\n",
        "Test_Data=[]\n",
        "for s in Final_DataFrame[\"Features\"]:\n",
        "  l=eval(s.replace(\" \",\",\"))\n",
        "  Test_Data.append(l)\n",
        "  i+=1\n",
        "Final_Data_Sample=numpy.array(Test_Data)\n",
        "Final_Data_Sample.resize((36486,18,9))\n",
        "print(Final_Data_Sample.shape)\n",
        "print(one_hot_encoded.shape)\n",
        "Train_Set_Data,Test_Set_Data,Train_Set_Label,Test_Set_Label=train_test_split(Final_Data_Sample,one_hot_encoded)\n",
        "print(Train_Set_Data.shape)\n",
        "print(Test_Set_Data.shape)\n",
        "print(Train_Set_Label.shape)\n",
        "print(Test_Set_Label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(layers.Conv1D(256,padding='same',kernel_size=5,activation=\"relu\"))\n",
        "model.add(layers.MaxPooling1D(pool_size=3,strides=2,padding=\"same\"))\n",
        "model.add(layers.Conv1D(128,padding='same',kernel_size=5,activation=\"relu\"))\n",
        "model.add(layers.MaxPooling1D(pool_size=3,strides=2,padding=\"same\"))\n",
        "model.add(layers.Conv1D(128,padding='same',kernel_size=5,activation=\"relu\"))\n",
        "model.add(layers.MaxPooling1D(pool_size=3,strides=2,padding=\"same\"))\n",
        "model.add(layers.Conv1D(64,padding='same',kernel_size=5,activation=\"relu\"))\n",
        "model.add(layers.MaxPooling1D(pool_size=3,strides=2,padding=\"same\"))\n",
        "model.add(layers.Dropout(rate=0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(8, activation=\"softmax\"))\n",
        "model.compile(Adam(learning_rate=0.00015),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=1, min_lr=0.0000000000001)\n",
        "es=EarlyStopping(monitor='loss')\n",
        "history=model.fit(Train_Set_Data, Train_Set_Label, batch_size=32, epochs=100, validation_data=(Test_Set_Data, Test_Set_Label), callbacks=[rlrp],shuffle=True)"
      ],
      "metadata": {
        "id": "M6dk3ooI2SWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}